# **Understanding Tunneling and How ngrok Works**

When you run a service on your local machine, normally no outside device can directly reach it due to NAT (Network Address Translation) and firewall rules. **Tunneling** solves this by forwarding traffic from a public endpoint to your local machine. **Ngrok** is a popular tunneling tool that provides a public URL (or TCP address) and securely tunnels traffic to a specified local port. In this deep dive, we’ll explore how ngrok establishes these tunnels, the protocols and technologies it uses (HTTP(S), TCP, TLS, WebSockets, etc.), how it maintains and secures the connection, and how data flows in both HTTP and TCP tunnel scenarios. We’ll also discuss multiplexing (handling multiple connections), NAT traversal, connection retries, and tunnel lifecycle management. Clear network diagrams are provided for both HTTP and TCP tunnels to illustrate **control paths** (management connections) and **data paths** (the forwarded traffic).

## **1\. Establishing a Tunnel: Ngrok Client and Cloud Server Connection**

When you start ngrok on your local machine (the **ngrok client or agent**), you specify the local port (or application) to expose. Ngrok then **initiates** a connection from your machine out to the ngrok cloud service. This is a crucial point: since the connection is initiated from inside, it easily traverses NAT and firewalls (outbound connections on port 443 are almost always allowed). By default, ngrok opens a **TLS-encrypted connection on port 443** to the ngrok cloud – making its traffic resemble normal HTTPS and avoiding filtering. In restrictive corporate networks, ngrok can even use an HTTP proxy (via the HTTP CONNECT method) to reach its servers.

On startup, the ngrok client resolves a regional server address (like `connect.us.ngrok-agent.com` or historically `tunnel.us.ngrok.com`) and performs a TLS handshake on port 443\. Once the secure channel is established, the client **authenticates** to the ngrok service using an **authtoken** (a secret key from your ngrok account). This proves your identity and allows ngrok to apply your account’s settings (like reserved domains or endpoints). After authentication, the client **registers the desired tunnels**: it sends messages indicating what kind of tunnel it wants (HTTP, HTTPS, TCP, etc.), possibly including options like subdomain or auth credentials for the tunnel. The ngrok server then allocates a public endpoint for each requested tunnel. For example, it might reserve a subdomain on `*.ngrok.io` for an HTTP tunnel, or assign an address like `0.tcp.ngrok.io:<port>` for a TCP tunnel. The client receives these details and displays the forward URL to you.

At this point, the **tunnel is established but idle**. On the ngrok service side, there’s now a public listener (an entry in ngrok’s routing table) for your tunnel. On your side, the ngrok client keeps a **persistent control connection** open to ngrok. This control connection is a long-lived TLS channel that remains active as long as the tunnel is running. Its job is to control and monitor the tunnel: it carries heartbeats to keep the connection alive, and it’s used to coordinate new inbound connections. The control connection is separate from the actual tunneled traffic; think of it as the command channel between client and server.

**NAT Traversal:** Because the ngrok client initiates all connections, you don’t need to configure your router or firewall – no inbound ports are opened. Even in very locked-down networks, ngrok works by **masquerading as HTTPS** on port 443\. This is how ngrok **traverses NAT** and firewalls without special tricks: it piggybacks on an outbound TLS connection that most networks allow. (In scenarios with only HTTP proxy access, ngrok can tunnel through the proxy as mentioned.)

**Multiple Tunnels:** A single ngrok client can establish **multiple tunnels simultaneously** (e.g. exposing several local services) over the same control connection. In ngrok’s config you can define multiple tunnels (each with its own protocol and port) and start them together. Ngrok’s protocol and control channel are designed to handle multiple tunnel definitions after the initial authentication.

## **2\. Protocols and Technologies Under the Hood**

Ngrok uses a mix of protocols to forward traffic seamlessly:

* **TCP:** At a low level, ngrok’s tunnels ultimately transmit bytes over TCP connections. For example, when exposing an SSH server or database, ngrok simply forwards raw TCP streams. Even HTTP traffic is carried over TCP/IP.

* **TLS (SSL):** All traffic between the ngrok client and ngrok server is encrypted with TLS. This applies to both the control connection and the tunnels themselves. Ngrok v2 made TLS mandatory for its client connections, running everything over port 443 to appear as regular HTTPS. This end-to-end encryption between your agent and the cloud ensures that no intermediary can snoop on the tunnel’s content. The ngrok client verifies the ngrok server’s TLS certificate on connect, and you can even configure mutual TLS in advanced setups. (Ngrok’s cloud uses wildcard or SAN certificates to handle the `*.ngrok.io` subdomains for user-facing endpoints.)

* **HTTP/HTTPS:** When you create an **HTTP tunnel**, ngrok acts as a reverse HTTP proxy. The public URL it gives (say `https://abcd-1234.ngrok.io`) will be accessible via HTTP or HTTPS. Ngrok’s server will terminate the HTTP(S) request from the end user and then forward it through the tunnel to your local server. By default, ngrok ensures that even HTTP tunnels are served securely to end users: if someone visits the `http://` URL, it often redirects or upgrades to `https://` (and ngrok’s default subdomains come with HTTPS support and a valid certificate). For **HTTPS tunnels** (where you specifically want end-to-end encryption to your app), ngrok can also operate without terminating TLS – but typically, for inspection and routing, it does terminate at the edge then re-encrypts to the client.

* **WebSockets:** WebSocket connections are supported out-of-the-box over HTTP tunnels. A WebSocket is essentially an upgraded HTTP connection. Ngrok’s server will handle the HTTP Upgrade handshake and then treat the WebSocket like a persistent TCP stream over the tunnel. No special configuration is needed for WebSockets; they will be forwarded just like normal HTTP traffic (after the initial HTTP upgrade).

* **Custom protocols (TLS tunnels):** Ngrok can also forward TLS connections without knowing the underlying protocol. For example, you can use `ngrok tls` to forward TLS-encrypted traffic (like smtps or any custom TLS service) – in that case ngrok doesn’t terminate the TLS at the edge; it passes it through to your local service. This is similar to TCP mode but specifically for TLS-based protocols, and it ensures end-to-end TLS encryption (ngrok is just piping bytes).

* **HTTP/2 and gRPC:** Ngrok’s newer versions support HTTP/2 between the ngrok agent and your local service (to improve efficiency) if you enable it. By default, the agent will talk HTTP/1.1 to your app, but you can enable cleartext HTTP/2 to your app for better performance in forwarding (since the TLS is already handled at ngrok’s edge). For end users connecting to ngrok’s public URL, ngrok’s edge does support HTTP/2 (over TLS) for incoming requests, but internally each incoming connection is typically matched to one tunnel connection.

* **Websocket-to-TCP converter:** A niche but interesting feature is that ngrok offers a “Websocket TCP Converter” which lets browser JavaScript connect via WebSocket to ngrok and ngrok will bridge that to a raw TCP service. This is more of a specialized use-case, effectively translating a ws:// connection into a TCP stream to a local service.

In summary, **ngrok acts as a sophisticated reverse proxy**. It uses TLS tunnels to securely carry arbitrary protocols. For HTTP, it behaves like an HTTPS-\>HTTP reverse proxy (with added features like rewriting URLs, providing a web interface to inspect traffic, etc.), and for raw TCP it behaves like a port forwarder. All of this is managed over a control channel and one or more data channels (described next).

## **3\. Tunnel Lifecycle: Establishment, Maintenance, and Teardown**

Once the ngrok client and server have set up the tunnel (via the control connection negotiation), the system enters the **maintenance** phase. The control connection remains open, and ngrok may send periodic **keepalive pings** over it to ensure neither side times out the idle connection. This helps detect if the link goes down (so ngrok can alert you or attempt reconnect).

**Establishing Data Connections:** When a user on the internet tries to access your public endpoint, the ngrok server must **bridge that incoming connection to your client**. Initially in ngrok’s early design, this was done on-demand: the server would send a message over the control channel to the client like “hey, I have a new incoming connection, please open a proxy connection”. The client would then initiate a new TCP connection back to the server for that particular tunnel traffic, and once connected, the server would link the user’s connection to this new “proxy” connection. While functional, this incurred latency (multiple round trips: server-to-client message, new TCP handshake, new TLS handshake) which in some cases added up to \~1 second delay for the first byte.

To improve performance, **ngrok v2 introduced connection pooling / pre-opening**. Now, the ngrok client typically opens a few **data connections** in advance, parallel to the control connection. These are additional TLS connections to the ngrok cloud held in a pool, ready to carry traffic. When an incoming request arrives, the server can immediately assign it to one of these already-open data channels, eliminating the startup latency. It then sends a command on the control channel for the client to **open a replacement** connection to keep the pool filled. This way, there’s usually a spare tunnel connection available, making incoming requests almost instantaneous to forward.

Each data connection is itself a TLS-secured connection (so effectively, you have multiple TLS tunnels within the overall session). The control channel orchestrates this but the heavy lifting (actual data bytes) goes over the data connections.

**Multiplexing:** It’s worth clarifying how ngrok multiplexes tunnels and connections. Ngrok’s protocol can handle multiple logical tunnels and multiple simultaneous streams. However, it doesn’t typically multiplex multiple streams *over a single TCP connection* (as HTTP/2 would); instead it uses multiple TCP connections (the pool) to handle concurrency. So, if two different users hit your endpoint at the same time, they will be serviced by two separate data TCP connections (or a single connection in quick succession if HTTP keep-alive is used – explained later). The control channel itself might also carry lightweight messages (like status, or your client’s requests to start/stop tunnels), but not the bulk data. This separation ensures that heavy traffic on a data channel doesn’t block control messages and allows better parallelism on multi-core servers.

**Health and Reconnection:** Ngrok monitors the tunnel health. If the control connection drops (say your internet blips), the ngrok client will attempt to reconnect automatically. It uses an exponential backoff for retries to avoid hammering. During downtime, the public endpoint will typically show an error if accessed (since the server knows no client is attached). When the client reconnects (with the same authtoken), ngrok may restore the previous tunnel endpoints if possible. In paid plans with reserved domains/ports, the endpoint is fixed so reconnecting is seamless; in free mode with ephemeral subdomains, a reconnect might give a new URL (unless it’s a short interruption and the server holds it for a bit).

**Closing the Tunnel:** If you stop the ngrok client or it crashes, the control connection closes and all data connections close too. The ngrok server then **tears down** the public endpoint so it no longer forwards traffic. From the user side, any new requests will fail (DNS might still resolve the subdomain, but the ngrok server knows no client is there to service it). Ongoing connections, if any, are terminated. Ngrok’s server and client both clean up resources accordingly. If you simply close a specific tunnel (via API or by ending that process), similar cleanup happens for that endpoint alone.

Ngrok also provides an API (and web interface at `localhost:4040`) which can be used to introspect and even shut down tunnels remotely. For example, you could programmatically stop a tunnel via the Tunnel Sessions API, which instructs the agent to close things down.

## **4\. Routing Traffic from Public URL to Your Local Machine (HTTP vs TCP)**

Now let’s focus on how incoming traffic actually travels through the tunnel. We’ll start with an **HTTP/HTTPS tunnel**, since it’s the most common use-case, and then cover **TCP tunnels**. The diagram below illustrates an HTTP(S) request going through ngrok:

*Figure 1: How ngrok works (HTTP tunnel). An end user’s web request goes to an ngrok public URL, which forwards it through a secure tunnel to your local server. The response travels back the same way. (Source: Sendbird)*

### **HTTP(S) Tunnels and Routing**

1. **User Makes a Request:** A user (or an external service like a webhook provider) makes an HTTP/HTTPS request to the public URL provided by ngrok (e.g., `https://abcd-1234.ngrok.io/path`). This URL is a DNS name that resolves to an ngrok server IP. If the user is using HTTPS (which is default for ngrok’s URLs), the browser establishes a TLS connection to the ngrok server. Ngrok’s server presents a certificate for `*.ngrok.io` and completes the TLS handshake.

2. **Ngrok Server Receives the Request:** The ngrok edge server now has an incoming connection from the user. It determines **which tunnel** this is for. In an HTTP tunnel, the **Host header** (or the SNI in the TLS handshake) contains the subdomain (`abcd-1234.ngrok.io`) which maps to a specific tunnel/client. The ngrok server knows which connected ngrok client is responsible for that hostname. If it’s a paid custom domain, the hostname directly maps to your tunnel. If it’s a wildcard ngrok subdomain, the subdomain token (e.g. `abcd-1234`) was allocated to your session at tunnel setup. So the server effectively **routes the request to your tunnel** based on hostname (and path, in case of domain wildcard with multiple endpoints, though typically one subdomain \= one tunnel).

3. **Decoding or Relaying HTTP:** Ngrok’s behavior here depends on tunnel type:

   * For a normal HTTP tunnel, ngrok will **terminate the user’s HTTP request** at the edge. This means if it was HTTPS, it decrypts it, and now it has an HTTP request in hand. Ngrok can optionally inspect or modify it (for example, it *does not* forward Hop-by-Hop headers, and it may add `X-Forwarded-For` or other metadata). If you have set up HTTP authentication on the tunnel (e.g., `ngrok http --auth=username:password`), ngrok will check the request’s HTTP Basic Auth against those credentials and reject the request with 401 Unauthorized if it doesn’t match – this prevents unauthorized users from reaching your local service. Assuming the request is allowed, ngrok prepares to forward it.

   * If the tunnel was configured as an **“TLS tunnel”** (not common for HTTP services, more for other TLS apps), ngrok wouldn’t terminate the TLS – but in that case it also wouldn’t know about Host headers. So typically HTTP tunnels are terminating at ngrok.

4. **Forwarding to the Local Agent:** The ngrok server now needs to forward the request to the ngrok client over the **data connection**. If a data channel is already open and free (from the pool), it uses that; otherwise it may quickly ask the client to open one. The request’s raw bytes (HTTP request line, headers, body) are relayed over the TLS-encrypted tunnel connection to your ngrok client. Essentially, ngrok packages the HTTP request and sends it down the wire. In older versions, it had an explicit message format for “New request: \[some metadata\]” then the bytes; in newer versions, because each data connection is dedicated, it likely just streams the bytes immediately.

5. **Local Client Forwards to Local Server:** The ngrok client receives the incoming request data and then opens a connection to your **local application** on the specified port (e.g., localhost:3000). It then writes the HTTP request to your local server as if the client (browser) had connected directly. From your application’s perspective, it’s just receiving an HTTP request on its port. (Ngrok by default adds headers like `X-Original-Host` or `X-Forwarded-For` to tell your app the original Host and client IP – useful for logging).

6. **Local Server Response:** Your application generates an HTTP response and sends it back on the same local TCP connection to the ngrok client. This could be HTML, JSON, an image, etc., just normal HTTP response bytes.

7. **Return through the Tunnel:** The ngrok client now streams the response bytes back over the secure tunnel (the same data connection that carried the request). Since that connection is TLS, the payload is encrypted on the wire. The ngrok server receives the bytes and if it had terminated the HTTP, it now has the response HTTP message. It sends the response back to the user’s HTTP connection. If the user was using HTTPS, the ngrok server encrypts the response into that TLS connection to the user.

8. **User Receives Response:** The end-user’s browser (or client) gets the HTTP response as if it came directly from the `ngrok.io` server. From the user’s perspective, they made a request to some host and got a valid response. They don’t need to know that the server processing the request was actually on a dev machine behind NAT.

**Efficiency:** In the above flow, note that after the first request, HTTP keep-alive might be in effect. Ngrok’s edge will often keep the TCP (or TLS) connection open with the user for a short time. The ngrok client likely also keeps the local connection open. This means subsequent requests (on the same HTTP tunnel) could reuse the existing data connection (without needing a new handshake each time) – **ngrok can tunnel multiple HTTP requests serially over one data TCP connection** if the user’s connection is kept alive. However, if multiple requests come in truly concurrently (e.g., two separate users or two parallel connections), that’s where multiple data channels in the pool are used concurrently.

**Websockets:** If the HTTP upgrade to WebSocket occurs, after step 4, the ngrok client will connect to your local WebSocket server and then simply shuttle messages back and forth. The tunnel data connection stays open until the WebSocket closes. It’s effectively like a long-lived TCP stream at that point.

### **TCP Tunnels and Routing**

For **TCP tunnels**, the flow is similar in concept but simpler in terms of content (no HTTP parsing). Ngrok will provide an address like `tcp://[region].ngrok.io:xxxxx` to connect to. The diagram below shows the data flow for a TCP tunnel (for example, using ngrok to expose an SSH server):

*Figure 2: Ngrok TCP tunnel concept. A TCP client (e.g. SSH) connects to a unique ngrok address (hostname:port). Ngrok’s server forwards the raw TCP stream through the secure tunnel to the local service (e.g. SSH daemon). Responses go back likewise. (Source: Requestly)*

1. **User Connects to TCP Address:** The user (or client program) resolves the provided ngrok TCP address (for instance `2.tcp.ngrok.io:15000`). This hostname maps to an ngrok server. The user’s TCP client then initiates a TCP connection to that IP and port. There’s no HTTP or higher protocol negotiation with ngrok’s edge – it’s a direct TCP connect. (If it’s an SSH client, it will start the SSH handshake after connection; if it’s MySQL client, it’ll start that protocol, etc.)

2. **Ngrok Server Accepts Connection:** The ngrok server listening on that port accepts the incoming TCP connection. It identifies which account/tunnel that port is associated with (ngrok knows port 15000, for example, is reserved for your tunnel by the control session). At this point, ngrok’s server doesn’t interpret the data (it’s not HTTP, it’s just bytes of some protocol). Its job is just to pipe data.

3. **Bridging to Tunnel:** The server then takes one of the established **data connections** from your client (or asks for a new one) just like in the HTTP case. It binds the user’s TCP connection to this data channel. From here on, whatever bytes come from the user will be forwarded to your ngrok client over the TLS-encrypted tunnel.

4. **Local Client Forwards to App:** The ngrok client receives the bytes and simply writes them to the local port you specified when starting the tunnel (say localhost:22 for SSH). Your local service (SSH server) sees an incoming connection and protocol bytes as if the client connected directly. The key difference from HTTP is that ngrok is not “terminating” or parsing anything at the edge – it treats it as opaque data.

5. **Response Path:** Any bytes the local server writes back are read by the ngrok client and sent back over the TLS tunnel to the ngrok server, which then writes them to the user’s TCP socket. This continues back and forth as long as the session is open.

From the perspective of the local TCP service, the source IP will appear as the ngrok client (since it’s the one actually connecting to it). Ngrok can’t easily insert the real client IP at the TCP layer (there’s no equivalent of X-Forwarded-For for raw TCP), unless the protocol itself has a means (some protocols allow proxy headers, but generally not). So for TCP tunnels, you may not know the real client’s IP on the app side (for SSH it’s fine; you’ll see the ngrok client’s IP which is local anyway).

**TCP vs HTTP differences:** One big difference is that **HTTP tunnels share a hostname** (like `ngrok.io`) among many users, so ngrok must inspect Host headers or have unique subdomains to route correctly. But **TCP tunnels use a unique port per user (or per reserved address)**, so the server can route purely by port number. The data is forwarded without needing content inspection. Another difference is that HTTP tunnels often terminate TLS at the edge (for the convenience of providing an HTTPS URL and features like inspection, compression, etc.), whereas TCP tunnels do not terminate the protocol – if you run an SSL/TLS service over a TCP tunnel, it remains end-to-end encrypted (ngrok sees only gibberish and just relays it).

Ngrok’s paid plans allow reserving a specific TCP address (static hostname:port) for your use. In free mode, the TCP address may be randomly assigned each time you start a tunnel. Either way, once established, the mechanics are as described.

## **5\. Responses, Multiplexing, and Performance Considerations**

In both HTTP and TCP tunnels, the **response data travels back through the same tunnel connection** that carried the request. Tunnels are fully bidirectional. Once a user’s connection is paired to an ngrok data connection, it’s as if you have a pipe: data flows in both directions until the connection is closed. This means HTTP responses, TCP server messages, etc., all go back through the ngrok cloud to the user.

Ngrok’s design handles **multiple simultaneous connections** efficiently:

* The **control channel** (red dashed line in the diagrams) is single but lightweight; it’s not used for bulk data. It remains available to coordinate new connections even if data channels are busy.

* **Data channels** are opened in parallel to handle concurrent traffic. If you expect high concurrency, the ngrok agent can maintain a larger pool of ready connections. (In older ngrok, a burst of many connections could saturate it because each needed a new TLS handshake – now mitigated by the pooling mechanism.)

**Multiplexing on a single connection**: Ngrok v2 does not typically multiplex different user streams on one TCP connection (that would require a custom framing protocol, or using something like HTTP/2 or WebSocket framing between client and server). Instead, it keeps things simple by using multiple connections. This avoids head-of-line blocking and leverages TCP parallelism. However, within a single HTTP keep-alive session, multiple requests are served sequentially on one connection, which is fine for things like a browser loading images (each image could be a separate connection though, depending on HTTP/2 or not).

There is a project exploring using QUIC (UDP-based) to carry tunnels (QUIC could allow multiplexing streams on one connection). The community has experimented with that (as seen in some ngrok-like implementations), but as of now ngrok uses TCP+TLS primarily.

**Connection Limits:** Note that ngrok free plan has limits on the number of connections per minute to prevent abuse. If you exceed that (for example, rapidly opening and closing many connections), you might hit “Too Many Connections” errors. This is not a technical limit of the protocol per se, but an imposed rate-limit.

## **6\. Security: Encryption and Authentication Details**

Security is a core aspect of ngrok’s design:

* **Encryption:** All tunnel traffic is encrypted with strong TLS (typically TLS 1.2+). From your local agent to ngrok’s cloud, it’s always TLS – this protects against eavesdroppers on your local network or ISP. For the user-facing side of an HTTP tunnel, ngrok provides HTTPS so that end-users also have encryption from their browser to the cloud. In effect, in an HTTPS \-\> HTTP tunnel scenario, the data is encrypted from the user to the ngrok server, then (after decryption) immediately re-encrypted in the tunnel to your client, then possibly goes unencrypted to your local server (since that might be plain HTTP on localhost). Thus, two layers of TLS protect the data across the internet. If you want end-to-end, you can either run your local server with TLS or use ngrok’s TCP/tls tunnel modes to avoid the break in the middle.

* **Authentication (Tunnel Level):** Ngrok requires an **authtoken** for the client to connect to the service (except maybe in older v1 which had anonymous usage, v2/v3 require accounts). This token is like a password that identifies you and is configured via `ngrok config add-authtoken`. It prevents unauthorized use of your ngrok account and tunnels. Moreover, ngrok allows you to secure individual tunnels. For HTTP tunnels, you can require HTTP Basic Auth on the public URL (ngrok will demand a username/password from anyone trying to access, as configured). You can also restrict access by IP address with ACLs or IP policies for advanced plans, ensuring only certain IPs can connect.

* **Authentication (Agent \<-\> Server):** The ngrok client authenticates the server too – it checks the server’s TLS cert chain. Ngrok’s official client is hardcoded to trust the ngrok.com CA for that purpose (so it won’t connect to imposter servers). In private/self-hosted ngrok, you’d have your own CA. There is also an option for mutual TLS where the ngrok server can require client certs (not typically used for the public service, but possible in enterprise setups).

* **Tunnel Isolation:** Each tunnel connection is isolated to your session. Other ngrok users cannot hijack your tunnel because they don’t have your authtoken and the session ID. Even if two users choose the same subdomain (on free plan, you can’t really choose; on paid, if you have a reserved domain that’s yours alone), ngrok ensures one user’s client can’t connect to another’s tunnel.

* **Data Integrity:** Because it’s TLS, any tampering with data in transit would be detected (TLS would fail). Ngrok also has measures to prevent certain attacks; for example, it uses random subdomains that are hard to guess (plus you can add your own auth) so that others can’t easily find and abuse your tunnel. It also will close the tunnel if the control channel dies – preventing stale forwarding.

* **Lifecycle Security:** If you stop a tunnel, ngrok won’t accidentally keep it open. If you revoke an authtoken from your account, any clients using it should drop (the server will refuse them). Ngrok also regularly updates its client for security patches (and it even has an update check built-in).

* **NAT Security:** One often raised concern is that opening a tunnel is like punching a hole through your firewall. Ngrok mitigates this by **only allowing traffic that goes through its cloud (which you have authenticated)**. No one can directly reach your machine except via the ngrok service. You effectively outsource the security to ngrok’s cloud – which provides goodies like DDoS protection, IP filtering, and inspection. This is generally safer than doing a raw port-forward on your router, because ngrok can act as a guard in front of your service.

* **Introspection and Filtering:** Ngrok’s web interface (`localhost:4040`) and inspector allow you to review requests and responses. This interface itself is local and secure. For paid plans, you can enforce things like IP allowlists or even add OAuth on the tunnel (so that Google/GitHub login is required before users can access your tunnel) – ngrok’s server handles that OAuth flow on your behalf.

In conclusion, ngrok’s tunneling architecture involves a **control plane** (for setup and management) and a **data plane** (for actual traffic). The ngrok client and server maintain a secure control channel that orchestrates the creation of one or more TLS-encrypted data tunnels. Through these tunnels, ngrok forwards requests from a public endpoint to your local app and relays responses back, giving the illusion that your local server is globally accessible. It handles HTTP and TCP slightly differently (terminating and proxying HTTP, versus pure forwarding for TCP), but the end result is the same: **a secure, reliable connection from the internet to your once-isolated local service**. This is done with careful attention to security (TLS, authtokens, authentication options) and performance (connection pooling, efficient routing), making ngrok a powerful tool for developers needing to expose local services to the world.

